{
    "configs": [
        {
            "accumulate_grad_batches": 2,
            "base_type": "microsoft/deberta-v3-large",
            "batch_size": 8,
            "epochs": 10,
            "l2_regularization": 0,
            "learning_rate": 5e-6,
            "max_seq_length": 200,
            "max_depth": 2,
            "augment_method": "raw_decode",
            "scheduler_warmup_proportion": 0,
            "load": false,
            "optimizer_class": "AdamW",
            "seed": 697474,
            "save": 5,

            "bespoke_base_checkpoint": "/home/mlw0504/data/workspace/knowledge_aug/train_social_iqa_augment/0/checkpoint/epoch=01-val_accuracy-val_accuracy=0.831.ckpt",
            "bespoke_optimizer_class": "AdamW",
            "bespoke_learning_rate": 5e-6,
            "bespoke_l2_regularization": 0,
            "bespoke_top_k": 8,
            "bespoke_min_similarity": 0.58,
            "bespoke_accumulate_grad_batches": 1,
            "bespoke_iterations": 2,
            "bespoke_batch_size": 8
        }
    ],
    "override_saved_config": {"0": {"max_seq_length": 512}},
    "early_stopping_patience": 15,
    "gpus": [0],
    "stages": [
        "social_iqa_bespoke_augment"
    ],
    "working_directory": "/home/mlw0504/data/workspace/knowledge_aug/train_social_iqa_bespoke_augment"
}
